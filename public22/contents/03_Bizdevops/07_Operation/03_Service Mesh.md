# Service Mesh

마이크로서비스 구성 요소간에 상호 통신을 위해서는 서비스 디스커버리, 서비스 라우팅, 트래픽 관리, 보안등의 요구사항을 
처리 할 수 있는 메커니즘이 필요하다. 이를 위해 **Service Mesh**로 알려진 기능이 마이크로서비스 아키텍처에 적용된다.

마이크로서비스에서 가장 복잡한 것은 구축 및 배치가 아니다. 마이크로서비스가 독립적으로 배포되면 Docker 컨테이너
에서 실행되는 100개의 마이크로서비스가 Kubernetes를 사용하여 관리 될 수 있다.
 마이크로 서비스 아키텍처가 가지는 모든 이점을 통해 모든 것을 관리하는 것은 어렵다. 
 트랜잭션이 실패하면 연결이 끊기는 부분, 특정 요청이 실패한 이유, 대기시간 문제가 있는 곳을 찾는 문제 등 해결하기 어려운 문제가 많다. 
 그렇기 때문에 서비스 계층을 추상화하고 서비스 간의 통신을 관리해야 할 필요성이 있다.

Service Mesh는 모든 서비스의 인프라 레이어로서 두 서비스간의 통신을 처리한다. 이는 서비스A에서 서비스 B로의
요청(TCP/IP용어로 패킷)의 안정적인 전달을 처리한다. 실질적으로 Service Mesh는 Mesh의 일부인 서비스와
병렬로 프록시를 배치함으로써 구현된다. 
응용프로그램 / 서비스는 프록시를 인식할 필요가 없으며, 응용 프로그램 코드에서 변경이 필요하지 않다. 

이는 큰 장점이다.

## **API Management 와 Service Mesh**

API Gateway에서도 라우팅, 트래픽 관리, 보안, 서비스 디스커버리와 같은 다양한 요구사항을 처리 할 수 있는 메커니즘을
제공한다. Service Mesh와 API gateway의 역할 상의 차이점은 다음과 같다.

### **\[API Management\]**

API Gateway는 API 관리 Manager와 다른 보안 컴포넌트, 인증컴포넌트들과 한 세트로 묶여서 API Management라
부르기도 한다. API Management 는 응용 프로그램의 진입 포인트를 관리하고, 응용 프로그램 자체가 다른 어플리케이션에
의해 사용 될 수 있도록 하는 방법을 관리한다. 예를 들어 응용 프로그램 사용자는 직접 클라이언트 또는 포털을
통해 사용할 수 있는 API를 기반으로 응용프로그램에 접근 또는 제어 할 수 있다. 즉, API Management에서는
응용프로그램에 대한 단일 엔드포인트를 제공하여, 응용프로그램을 포함한 시스템에 대한 아키텍처를 캡슐화하여, 
각 클라이언트 또는 포탈에 맞게 적용된 API를 제공하며, 여기에는 인증, 모니터링, 로드밸런싱, 캐싱, 요청관리, 정적응답
처리와 같은 기능을 제공한다. API Management 에서 API Gateway를 마이크로서비스 앞에 두어, API Gateway가 
모든 클라이언트의 요청의 진입점이 되도록 한다.

API Management에서는 이러한 사용자를 개별적으로 트래픽, 엑세스 제어 측면에서 관리 할 수 있다. 또 한, API
Management에서 관리되는 API를 추상적으로 유지하고, 어플리케이션에 호출 하는 과정에 대해 요청 라우팅과 프로토콜
변환작업을 수행한다.

즉, API Management는 마이크로서비스 구성 요소 그룹의 외부 경계를 보호하고 제어하는 역할을 담당한다.

### **\[Service Mesh\]**

API Management가 마이크로서비스 구성 요소 그룹의 외부 경계에서 보호하고 제어하는 역할을 수행하는 것과 달리,
Service Mesh는 아래 그림에서와 같이 경계 내부에서 역할을 수행한다.

![](/img/03_Bizdevops/07/03/image100.png)

모놀리식 아키텍처의 애플리케이션을 소형의 마이크로서비스 구성요소로 나누게 되면 각 구성요소가 다른 구성요소와 완전히 분리되는
이점을 얻게 된다. 이는 마이크로서비스 아키텍처가 제공하는 민첩성, 확장성, 복원성의 이점을 실현할 수 있다.
마이크로서비스는 독립적으로 구축되어 서로 커뮤니케이션 하게 되고, 장애가 개별적으로 발생하기 때문에 전체의 운영
중단으로 확대 되지 않는다. 서비스간의 커뮤니케이션이 바로 마이크로서비스를 가능하도록 하는 핵심이다. 커뮤니케이션을 통제하는
로직은 Service Mesh없이 각 서비스에 코딩 될 수 있다. 많은 라이브러리와 프레임워크를 이용하여 Circit
Breaker 패턴을 구현할 수 있으며, 로드밸런싱 및 버전 기반 라우팅 기능을 구현할 수있다. 하지만 이러한 기능 구현은
마이크로서비스 구성요소에 내장되어 코드의 복잡성을 증가시킨다.

마이크로서비스 아키텍처에서는 kubernetes와 같은 컨테이너 오케스트레이션 도구를 통해 마이크로서비스 구성요소들을 대규모로
관리한다. Kubernetes 자체는 런타임 환경에서 다른 마이크로서비스에 대한 Service Discovery 기능을
기본으로 제공하고, 컨테이너에 대한 동적 로드 밸런싱 기능을 제공한다.

Service Mesh는 애플리케이션 런타임 환경에서 새로운 기능을 추가로 요구하지 않는다. 아키텍처 내의 애플리케이션에는 요청이
A 지점에서 B지점으로 전달되는 방식을 지정하는 룰이 필요하다. Service Mesh는 개별 서비스로부터 서비스 간
커뮤니케이션을 통제하는 로직을 통해 인프라 계층에 이를 추상화하는 역할을 담당한다. Service
Mesh는 어플리케이션 내부 경계에서 마이크로서비스 간의 모든 직접적인 상호통신을 차단하고, 라우팅, 복원력 및 보안 패턴과 같은
요소를 마이크로서비스 자체와 완전히 독립적으로 도입하여 관리한다.

**API Management, Service Mesh 비교**

![](/img/03_Bizdevops/07/03/image101.png)

API Management와 Service Mesh는 서로 다른 범위에서 적용된다. API Management는 마이크로서비스
그룹의 API가 다른 그룹에 노출되는 방식에 중점을 두며, Service Mesh는 그룹 안에서 라우팅을 제공한다.

<span class="underline">API Management 는 일반적으로 Gateway 프록시 패턴을 사용해서
수행</span>된다. API 호출자는 API 구현내용을 알 필요 없다. Gateway를 호출하는 방법만 알면
Gateway가 API 구현내용에 대한 리디렉션을 대신 수행한다. 트래픽 관리 또는 경로 기반 라우팅 같은 상호 연결 패턴은
API Gateway에 의해 수행된다. (API gateway 구성은 API Management의 구성요소)

이에 반해 <span class="underline">Service Mesh는 일반적으로 Side Car Proxy 패턴을
사용</span>한다. Gateway가 없으며, 호출자는 Mesh내에서 존재한다. 따라서 Mesh의 양쪽에는 호출자와
공급자가 있다. 호출자의 코드에는 공급자의 주소를 찾는 방법과 공급자의 호출에 대한 밸런싱을 유지하는 로직, 또한
재시도를 수행할지 또는 Circit Braker 와 같은 패턴을 구현할지 에 대한 내용이 들어가게된다. Service
Mesh를 이용하면 이런 Sevice Mesh기능을 제공하는 호출자의 코드는 어플리케이션 코드내 내장되는 것이 아니라
Sidecar와 같이 별개로 관리 된다. Sidecar의 작업의 대부분은 다운 스트림 호출을 관리하는 것이며, 이는 대부분의 상호
통신 패턴이 API Management에서와 같이 서버에서 관리되는 것이 아니라, 클라이언트에서 수행되고 있음을 의미한다.

다음은 API Management와 Service Mesh의 차이점에 대한
표이다.

|                   | API Management                                                     | Service Mesh                                                                |
| ----------------- | ------------------------------------------------------------------ | --------------------------------------------------------------------------- |
| Service Discovery | 사용자가 서비스를 사용할 수 있는 API를 자체적으로 제공함                                  | 필요한 서비스를 찾기 위해서는 클라이언트 Sidecar 에서 사용하는 서비스 레지스트리를 유지관리 해야 함                 |
| 라우팅 주체            | 서버 측                                                               | 요청하는 서비스                                                                    |
| 라우팅 구성요소          | 별도의 네트워크(hop)을 도입하는 독립적인 API gateway 구성요소                          | Local Network 스택의 일부가 되는 클라이언트의 sidecar                                     |
| 로드밸런싱             | API Gateway는 단일 엔드포인트를 제공하고, 로드밸런싱 구성요소에 요청을 리디렉션하여 로드밸런싱 구성요소가 처리 | 서비스 레지스트리에서 서비스 목록을 수신하고, 이를 기반으로 클라이언트 sidecar에서 로드밸런싱 알고리즘을 통해 수행         |
| 범위                | 하나의 API gateway가 많은 응용프로그램의 API를 노출                                | Kubernetes 네임스페이스 내의 컨테이너와 같이 응용프로그램이 밀접하게 관련된 마이크로서비스 구성요소 세트로 제한          |
| 네트워크              | 외부 네트워크와 내부 애플리케이션 네트워크 사이에 위치함                                    | 응용 프로그램의 네트워크 경계 내에서만 통신을 가능하게 함(예를 들어 Kubernetes 의 Namespace 네트워크 범위)      |
| 로그 및 매트릭          | API Gateway를 통한 전체 호출에 대한 집계                                       | Mesh 범위 내에서 교차 컴포넌트 추적                                                      |
| Analytics         | API 사용자, 공급자에 대한 모든 호출에 대해서 수집되고 분석 되어짐                            | Mesh 내 모든 마이크로서비스 구성요소에 대해 다른 별도 구성요소를 통해 분석할 수 있음 (데이터 정렬/분석은 mesh 역할이 아님) |

사용되는 보안 모델에도 차이가 있다. 예를 들어 API Management는 노출된 API를 보호하기 위해 HTTP인증,
OAuth 및 애플리케이션 카/패스워드 쌍과 같은 기술을 상용하는 반면에, Service Mesh는 상호 서비스간에 TLS를
시행하는데 사용되며 Mesh내 구성요소간 세부적인 역할 기반 엑세스 제어를 지원한다.

API Management (API Gateway)와 Service mesh는 서로 독립적인 역할을 가지고 있으며, 이들간의
경계를 파악하는 것이 매우 중요하다. API Gateway의 주된 목적은 네트워크 외부의 트래픽을 받아서 내부에
배포하는 것이고, Service Mesh는 네트워크 내의 트래픽을 라우팅하고 관리하는 데 있다. Service
Mesh는 API Gateway와 함께 작동하여, 외부 트래픽을 효율적으로 수신한 다음, 네트워크에서 트래픽을 효과적으로 라우팅
하도록 설계해야 한다. API Gateway와 Service Mesh가 있는 배포에서 클러스터 외부에서 들어오는 트래픽이 먼저
API Gateway를 통해 라우팅 된 다음, Service Mesh로 라우팅 된다. API Gateway는 인증, 라우팅 등의
오프로드 기능을 처리할 수 있는 반면에 Service Mesh는 마이크로서비스 아키텍처에 대한 세밀한 관찰과 제어 기능을
제공한다.

최근 추세를 보면 Service Mesh 기술이 매우 빠르게 발전하고 있어서 API Gateway의 일부 기능을 지원하고 있다.
Docker 컨테이너와 Kubernetes와 같은 컨테이너 오케스트레이션 툴을 사용하는 조직이 늘어남에 따라 Service
Mesh와 API Gateway 기능이 병합될 가능성이 높다.

**Service Mesh 패턴**

\[Library\]

![](/img/03_Bizdevops/07/03/image102.png)

라이브러리 방식은 간단하다. 각 마이크로 서비스 응용프로그램에는 Service Mesh 기능을 구현하는 라이브러리 코드가
포함된다.(Hystrix, Ribbon과 같은 라이브러리) 이는 하나의 개발 언어와 프레임워크 등의 환경에서 구현된
어플리케이션에 적합하다. 라이브러리 방식은 인프라 환경과의 많은 호환성을 필요로 하지 않는다. 컨테이너 오케스트레이션(eg.
Kubernetes)은 Hystrix 라이브러리가 적용되더라도 따로 설정하지 않아도 된다. 그러나 언어 사용에 있어서 라이브러리
방식은 제한이 있다. 이러한 라이브러리를 이용해 어플리케이션은 Service Mesh의 기능을 사용하게 되며, 이 작업은
마이크로서비스의 컨텍스트에서 수행되기 때문에 CPU, 메모리와 같은 리소스를 공정하게 할당하기가 쉽다.

**\[Node Agent (Shared host Proxy)\]**

![](/img/03_Bizdevops/07/03/image103.png)

노드 에이전트 방식에서 모든 노드(Container Instance, GCE)에서 실행되는 agent를 두고, 작업 부하를
처리한다. 이 방식에서 어플리케이션 구현 언어는 중요하지 않다. 노드 에이전트 방식의 대표 적인 예로 Linkerd
가 있다. 모든 노드에는 하나의 노드 Agent가 필요하기 떄문에 이 방식에서는 인프라와의 호환성이 필요하다. 수 백에서 수천
대의 인스턴스와 순간적으로 인스턴스를 다시 스케줄링 하는 오케스트레이션 도구에서 단일 요청이 서비스의 토폴로지를 따라가는
경로는 매우 복잡하며, 컨테이너를 사용하면 각 서비스를 쉽게 구성할 수 있기 때문에 라이브러리 방식은 마이크로서비스 환경에서
비효율적이다.

노드 에이전트 방식에서 Service Mesh는 TCP/IP와 유사하다. TCP 스택이 네트워크 종단점간에 바이트를 안정적으로
전달하는 메커니즘을 추상화하는 것처럼 Service Mesh는 서비스간에 안정적으로 요청을 전달하는 메커니즘을 추상화한다.
TCP와 마찬가지로 Service Mesh도 실제 페이로드나 인코딩 방법에 신경 쓰지 않는다. 응용 프로그램의 목표(A에서 B로
보내기와 같은)를 가지고 있으면 TCP와 마찬가지로 Service Mesh는 목표를 달성하는 동시에 오류도 처리한다. TCP
와 달리 Service Mesh는 그 외 응용 프로그램 런타임에 대한 가시성과 제어기능 등을 제공한다. Service
mesh의 목표는 서비스 커뮤니케이션을 보이지 않는 인프라 영역에서 모니터링, 관리 및 제어할 수 있는 일종의 레이어로
추상화는 데 있다.

노드 에이전트 방식의 작동 과정에 대한 이해를 돕기 위하여 Linkerd를 예로 들어 설명한다.

Linkerd를 통해 서비스에 대한 요청이 있을 때 다음과 같이 처리 된다.

\[1\] Linkerd는 동적 라우팅 규칙을 적용하여, 요청자가 의도한 서비스를 찾는다.

\[2\] 올바른 대상 서비스를 찾으면 Linkerd는 해당 서비스 엔드포인트에서 노드(GCE)의 해당 풀을 검색한다.

\[3\] Linkerd는 최근 요청에 대한 관찰된 대기시간을 포함하여 다양한 요인을 기반으로 빠른 응답을 반환할 가능성이 가장
높은 노드를 선택한다.

\[4\] Linkerd는 노드에 요청을 보내고 결과의 대기 시간과 응답 유형을 기록한다.

\[5\] 노드가 다운되거나 응답이 없거나 요청을 처리하지 못한 경우 Linkerd는 다른 노드에서 요청을 다시 시도한다.(단,
요청이 먹통인 경우 에만)

\[6\] 노드가 오류를 지속적으로 반환하는 경우 Linkerd는 이를 로드밸런싱 풀에서 제거하여 나중에 주기적으로 다시
시도한다.(예, 노드에서 일시적인 오류가 발생할 수 있음)

\[7\] 요청 마감시간이 경과하면 Linkerd는 추가 재시도를 하는 대신 사전에 요청을 실패 처리한다.

\[8\] Linkerd는 위의 모든 동작을 매트릭화하여, 중앙 집중식 매트릭 시스템에 전송한다.

노드 에이전트 방식의 경우 동일한 호스트에 많은 컨테이너가 존재하는 경우, Sidecar 방식에 비해 처리량이 높고, 리소스를
적게 사용한다. 그러나 노드에이전트(linkerd proxy)가 장애가 나는 경우 해당 호스트에 있는 모든 컨테이너에
요청을 전달 할 수 없게 되며, 다른 Service Mesh와 같이 사용할 수 없다.

**\[Sidecar (Recommended)\]**

![](/img/03_Bizdevops/07/03/image104.png)

Sidecar 방식은 Envoy와 함께 Istio에서 사용하는 방식이다. Sidecar 배포에서 모든 응용 프로그램 컨테이너에
추가로 Sidecar 컨테이너가 배포된다. Sidecar는 응용 프로그램 컨테이너로 들어오거나 나가는 모든 네트워크
트래픽을 처리한다. 이 방식은 라이브러리와 노드에이전트 방식과 큰 차이점을 가진다. 예를 들어 모든 노드에서 새
에이전트를 실행할 필요 없이 Sidecar를 배포할 수 있으므로(노드 에이전트를 배포하기 위해 인프라 전반에 협업이
필요하지 않음) 동일한 Sidecar의 복사 본을 여러 개 실행한다. 또한 Linkerd에서 마이크로서비스 그룹에
하나의 Service Mesh만을 사용하던 것과 달리 다른 Service Mesh와 같이 사용할 수 있다. Sidecar
방식에서 GKE의 경우, POD 정의에 프록시가 정의된다. 일반적으로 1Container 당 1 Sidecar 방식으로
사용되며, 단일 호스트로의 proxy오류 가능성을 제한하며, 동일한 호스트의 단일 호스트에는 영향을 미치지 않는다.

**Service Mesh 주요 기능**

Service Mesh의 주요한 목표는 서비스 통신 계층에 대한 가시성을 확보하고 동적으로 서비스를 디스커버리, 로드 밸런싱,
타임아웃처리, 폴백, 재시도, Circuit Breaker, 분산형 추적 과 같은 모든 마이크로서비스 통신 논리를 완벽하게
제어하는 데 있다. 서비스 간의 보안 정책 적용 및 가시성 확보 등은 트래픽 제어 및 trace 기능에 의해 제공된다.

GCP의 GKE는 이미 기본적인 Service Mesh를 가지고 있다. 그것은 ‘서비스(Service)’ 리소스 이다. 필요한
Pod/Task를 대상으로 서비스 검색을 제공하고, 요청에 대한 라운드로빈 방식으로 밸런싱을 처리한다. 서비스는 클러스터의 각
호스트에서 iptable을 관리하여 재시도 및 논리 연결 해제 없이 라운드 로빈 로드밸런싱 방식과 같은 기초적인 기능만을
지원하고, 앞에 나열한 Service Mesh풍부한 기능은 기대할 수 없다. 그러나 컨테이너 클러스터 환경에서 Service
Mesh(Linkerd, istio, consul)을 구현하면 다음과 같은 기능을 쓸 수 있다.

1)  HTTP/HTTPS

> Service Mesh 프록시는 발신 측에서 HTTPS 캡슐화를 관리하고 수신 측에서 TLS 종단을 관리하여 응용 프로그램의
> 구성요소가 일반 HTTP 또는 gRPC 및 기타 프로토콜을 사용할 수 있게 한다. 또한 전송 중 암호화에 신경 쓰지 않아도
> 된다. 암호화는 프록시에 의해 처리된다.

2)  보안 정책

> 프록시는 어떤 서비스가 다른 서비스 및 엔드포인트에 액세스하도록 허용되는지를 알고 허락되지 않은 트래픽을 거부한다.

3)  Circuit Breaking

> 오버로드된 서비스 또는 엔드포인트에 엑세스 할 때, 자동으로 백오프 (대기시간이 너무 길어서 과도한 로드로 인해 엔드포인트가
> 완전히 실패할 수 있는 요청이 증가하는 것을 피하기 위해서)

4)  지연시간 기반 로드밸런싱

> 각 대상의 대기시간을 무시하는 라운드 로빈 스타일의 로드밸런싱 대신 각 백엔드 대상의 응답시간에 따라 스마트한 로드밸런싱을
> 사용한다.

5)  대기열 기반의 로드밸런싱

> Service Mesh는 이전의 모든 요청을 보낸 곳과 처리 중이거나 완료 한 곳을 정확히 알고 있으므로 처리를 위해 가장
> 낮은 대기열을 가진 대상에 해당 로직을 기반으로 새로운 수신 요청을 보낸다.

6)  요청 라우팅

> HTTP 헤더를 읽어서 요청을 로드밸런서 뒤에 있는 특정 대상으로 라우팅한다. 이 기능을 이용해 카나리아 배포 테스트 등을 할
> 수 있다. Service Mesh에서 제공하는 가장 강력한 기능 중 하나이다.

7)  Health Check, 재시도

8)  매트릭 및 Trace

> 대기시간 매트릭, 요청 성공/오류율

**Service Mesh 종류**

서비스 매시는 크게 MS Azure Service Fabric과 같이 PaaS의 일부로서 서비스 코드에 포함되는 유형과
Netflix OSS와 같이 라이브러리로 구현되어 API호출을 통해 매시에 결합되는 유형 및 Istio, Linkerd와 같이
Side Code 프락시를 사용하여 메시 기능을 마이크로서비스에 주입하는 유형으로 분류된다.

![](/img/03_Bizdevops/07/03/image105.png)

**\[AWS App Mesh
([<span class="underline">https://aws.amazon.com/ko/app-mesh/features/</span>](https://aws.amazon.com/ko/app-mesh/features/))\]**

AWS App Mesh를 사용하면 다양한 유형의 컴퓨팅 인프라 전반에 구축된 서비스에 대한 일관된 가시성 및 네트워크 트래픽 제어
기능을 제공하여 손쉽게 서비스를 실행할 수 있으며, 모니터링 데이터 수집 방식이나 서비스 간에 트래픽이 라우팅 되는 방식을
변경하기 위해 애플리케이션 코드를 업데이트할 필요가 없다. App Mesh는 모니터링 데이터를 내보내도록 각
서비스를 구성하고, 애플리케이션 전반에 일관된 통신 제어 로직을 구현한다. 이를 통해 오류의 정확한 위치를 신속하게
찾아내고 오류가 있거나 코드 변경 사항을 배포해야 하는 경우 네트워크 트래픽을 자동으로 다시 라우팅 할 수 있다.

AWS Fargate, Amazon ECS, Amazon EKS, Kubernetes on EC2와 함께 App Mesh를
사용하면 규모에 맞춰 컨테이너화된 마이크로서비스를 효과적으로 사용할 수 있다.

AWS APP Mesh의 주요 기능은 다음과 같다.

1)  일관된 마이크로서비스 통신 : App Mesh는 통신 모니터링과 제어에 필요한 논리를 각각의 마이크로서비스 대한 모든
    네트워크 트래픽을 관리하는 프록시로 나눈다.

2)  오픈소스 프록시 : App Mesh는 마이크로서비스 컨테이너로 오가는 모든 트래픽을 관리하기 위해 오픈소스인 Envoy
    프록시를 설정한다.

3)  가시성 : App Mesh는 마이크로서비스 간 모든 통신에 대한 수치, 로그, 트레이스를 모으기 때문에 에러 발생 부분을
    빠르게 처리할 수 있다. 이 기능은 AWS 서비스와 오픈 소스를 이용하여 실행 가능하다.

4)  트래픽 제어 : App Mesh는 어플리케이션 내부 코드 수정이나 로드밸런서를 사용하는 일 없이 마이크로서비스들을 바로
    연결할 수 있도록 하며, 각 마이크로서비스가 시작할 때, 마이크로서비스의 프록시가 App Mesh에 연결하고
    어플리케이션 내 다른 마이크로서비스들의 위치를 담고 있는 데이터를 받는다.

**Istio
([<span class="underline">https://istio.io/docs/concepts/what-is-istio/</span>](https://istio.io/docs/concepts/what-is-istio/))**

Istio는 Google, IBM, Redhat, Lyft, VMware와 같이 다수의 대형업체들이 참여하여 Service
Mesh의 개념을 쉽게 구현할 수 있는 일종의 프레임워크(?)의 형태로 제공하는 오픈소스이다. 그리고 이를 통해 대규모의
마이크로서비스 환경이라고 하여도 서비스를 연결, 보안, 제어 및 관찰할 수 있는 방안을 쉽게 하도록 지원하고
있다.

Istio의 주요 기능은 다음과 같다.

1)  트래픽 관리 : Istio의 간단한 룰 설정과 트래픽 라우팅은 사용자로 하여금 서비스 간 트래픽과 API 요청의 흐름을
    조절할 수 있게 한다. Istio는 circuit breakers, timeouts, retries 같은 서비스
    레벨의 속성들의 설정을 단순화 하고, A/B Testing, Canary Rollouts, 백분위 단위의
    traffic 분산으로 단계적 rollouts 같은 중요한 일들을 설정하기 쉽도록 한다.

2)  보안 : Istio는 마이크로 서비스 간 통신의 인증, 승인, 암호화를 확장 가능한 방식으로 제공 및 관리할 수 있다.
    특히, Istio 가 기본적으로 기반 보안 통신 채널을 제공하므로 이를 통해 개발자는 애플리케이션 수준 보안에
    집중할 수 있으며, 별도의 보안에 대한 고민 없이도 Istio 가 안전한 보안 커뮤니케이션을 지원할 수 있다..

3)  관측 : Istio는 기본적으로 추적, 모니터링, 로깅을 제공 가능하며 이를 통해 Service Mesh 배포에 대한
    심층적인 정보를 제공하여 서비스의 성능과 다른 프로세스에 미치는 성능의 영향을 확인하고 문제를 빠르고 효과적으로
    감지 및 분류할 수 있도록 지원할 수 있다..

4)  플랫폼 지원 : Istio는 플랫폼에 독립적이고, 다양한 클라우드, On-premise, Kubernetes, Mesos
    같은 다양한 환경에서 돌아가도록 설계 되었다.

5)  통합 및 사용자 정의 : Istio의 정책 실행 구성요소는 ACLs, Logging, Monitoring, Quotas,
    Auditing 등 기존의 솔루션들과 통합되도록 확장 및 사용자 정의가 가능하다.

**Service Mesh 고려사항**

Service Mash Pattern에서 설명한 것처럼 Service Mesh 패턴은 다양하다. 패턴들을 크게 두 가지로 크게
분류하면 호스트 공유 프록시 패턴과 Side car 컨테이너 방식이라 할 수 있다.

![](/img/03_Bizdevops/07/03/image106.png)

**\[Host Shared Proxy 패턴\]**

Kubernetes 용어로는 Daemonset이라 부른다. 동일한 호스트에 많은 컨테이너가 존재하고 연결 풀링을 활용하여 처리량을
향상 시키는 경우에는 더 적게 리소스를 사용한다. 그러나 하나의 프록시가 실패하면 해당 호스트에 있는 모든 컨테이너들이 종료
된다. 대표적인 service mesh 제품은 linkerd이다.

**\[Sidecar 컨테이너 패턴\]**

메인 응용 어플리케이선 컨테이너 서비스와 함께 실행되도록 각 pod 또는 task 정의에 프록시가 주입된다. 단일 호스트로의
프록시 오류 가능성을 제한하며 동일한 호스트의 다른 호스트에는 영향을 미치지 않는다. Linkerd 역시 sidecar
컨테이너에 주입하여 사용할 수 있다. 이 방식의 대표적인 service mesh 제품은 istio이다.

**Service Mesh 구성에 따른 마이크로서비스 아키텍처 차이 **

이해를 돕기 위하여 아키텍처를 구성한 조직에서 일어날 수 있는 일을 시나리오로 작성하였다.

**\[Service Mesh 미 구성 아키텍처\]**

![](/img/03_Bizdevops/07/03/image107.png)

위 그림은 Service mesh가 고려되지 않은 마이크로서비스 아키텍처를 나타낸다. 방문자 패턴과 환경 설정을 학습하여
웹사이트에서 자신의 경험을 개인화하고, 사용자에게 좋아하는 주제 업데이트를 알리는 등의 일을 하는 응용
프로그램을 제공한다. 수천 개의 컨테이너와 수백 개의 노드에 퍼져 있는 모든 마이크로서비스들에서 발생하는 많은
복잡한 프로세스가 있다고 가정한다. 이 예에서 각 마이크로서비스에는 통신과 관련된 코드가 있다. 재시도 정책, 시간초과,
예외처리(네트워크 오류의 경우) 등을 설정한다. 또한 팀은 스칼라, goLang, Nodejs, java,
Python등 다양한 언어로 응용 프로그램 개발을 하고 있다. 모든 구성 요소는 네트워크를 통해 REST API 또는
gRPC를 통해 서로 통신할 수 있으며, 각 팀은 각각의 언어를 사용하여 자신의 구성요소에 비즈니스 로직 뿐만 아니라 통신
논리를 구현하는데 시간과 노력을 쏟아야하며, 서로 다른 라이브러리 및 기능을 공유할 수 없다.

**\[Service Mesh 적용 아키텍처\]**

![](/img/03_Bizdevops/07/03/image108.png)

이 아키텍처의 주요한 특징은 Service Mesh컨트롤 플레인(또는 일부 저장소의 구성 파일을 통해 선택한 도구 및 배포 방법에
따라 다름)을 통해 동일한 위치에서 프록시를 구성하고 업데이트 할 수 있다는 점이다. 모든 수천 개의 프록시에 대한 규칙을
지정하여 라우팅, 밸런싱, 매트릭 수집, 보안 정책, Circuit Breaker, 암호화 전송 등의 모든 작업은
클러스터 관리자가 적용한 규칙 집합을 따르게 된다.

마이크로서비스 통신 메커니즘을 별도의 아키텍처 계층으로 분리하는 Service Mesh의 개념은 수 천개의 프록시를 구성하고 유지
관리하는 복잡성을 감당할 만큼 유익한 지에 대한 의문이 들 수 있다.

Istio는 완벽한 기능을 가진 Service Mesh의 예이며, 모든 데이터 플레인 프록시를 관리하는 여러 마스터 구성요소를
가지고 있다. (프록시는 Envoy 또는 Linkerd가 될 수 있지만 기본적으로 Envoy를 사용)
