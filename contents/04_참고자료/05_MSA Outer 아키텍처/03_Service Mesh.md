## Service Mesh

마이크로서비스 구성 요소간에 상호 통신을 위해서는 서비스 디스커버리, 서비스 라우팅, 트래픽 관리, 보안등의 요구사항을 처리 할 수 있는 메커니즘이 필요합니다. 이를 위해 **Service Mesh**로 알려진 기능이 마이크로서비스 아키텍처에 적용됩니다.

마이크로서비스에서 가장 복잡한 것은 구축 및 배치가 아닙니다. 마이크로서비스가 독립적으로 배포되면 Docker 컨테이너에서 실행되는 100개의 마이크로서비스가 Kubernetes를 사용하여 관리 될 수 있습니다.

마이크로 서비스 아키텍처가 가지는 모든 이점을 통해 모든 것을 관리하는 것은 어렵습니다. 

트랜잭션이 실패하면 연결이 끊기는 부분, 특정 요청이 실패한 이유, 대기시간 문제가 있는 곳을 찾는 문제 등 해결하기 어려운 문제가 많다. 그렇기 때문에 서비스 계층을 추상화하고 서비스 간의 통신을 관리해야 할 필요성이 있습니다.

Service Mesh는 모든 서비스의 인프라 레이어로서 두 서비스간의 통신을 처리합니다. 이는 서비스A에서 서비스 B로의 요청(TCP/IP용어로 패킷)의 안정적인 전달을 처리합니다. 

실질적으로 Service Mesh는 Mesh의 일부인 서비스와 병렬로 프록시를 배치함으로써 구현됩니다. 응용프로그램 / 서비스는 프록시를 인식할 필요가 없으며, 응용 프로그램 코드에서 변경이 필요하지 않습니다. 

<br/>

### **API Management 와 Service Mesh**

API Gateway에서도 라우팅, 트래픽 관리, 보안, 서비스 디스커버리와 같은 다양한 요구사항을 처리 할 수 있는 메커니즘을 제공합니다. Service Mesh와 API gateway의 역할 상의 차이점은 다음과 같습니다.

#### **\[API Management\]**

API Gateway는 API 관리 Manager와 다른 보안 컴포넌트, 인증컴포넌트들과 한 세트로 묶여서 API Management라 부르기도 합니다. API Management 는 응용 프로그램의 진입 포인트를 관리하고, 응용 프로그램 자체가 다른 어플리케이션에 의해 사용 될 수 있도록 하는 방법을 관리합니다. 

예를 들어 응용 프로그램 사용자는 직접 클라이언트 또는 포털을 통해 사용할 수 있는 API를 기반으로 응용프로그램에 접근 또는 제어 할 수 있습니다. 

즉, API Management에서는 응용프로그램에 대한 단일 엔드포인트를 제공하여, 응용프로그램을 포함한 시스템에 대한 아키텍처를 캡슐화하여, 각 클라이언트 또는 포탈에 맞게 적용된 API를 제공하며, 여기에는 인증, 모니터링, 로드밸런싱, 캐싱, 요청관리, 정적응답 처리와 같은 기능을 제공합니다. 

API Management 에서 API Gateway를 마이크로서비스 앞에 두어, API Gateway가 모든 클라이언트의 요청의 진입점이 되도록 합니다.

API Management에서는 이러한 사용자를 개별적으로 트래픽, 엑세스 제어 측면에서 관리 할 수 있습니다. 또 한, API Management에서 관리되는 API를 추상적으로 유지하고, 어플리케이션에 호출 하는 과정에 대해 요청 라우팅과 프로토콜 변환작업을 수행합니다.

즉, API Management는 마이크로서비스 구성 요소 그룹의 외부 경계를 보호하고 제어하는 역할을 담당합니다.

<br/>

#### **\[Service Mesh\]**

API Management가 마이크로서비스 구성 요소 그룹의 외부 경계에서 보호하고 제어하는 역할을 수행하는 것과 달리, Service Mesh는 아래 그림에서와 같이 경계 내부에서 역할을 수행합니다.

<div style="text-align: center;">

![](/img/03_Bizdevops/07/03/image100.png)

</div>

모놀리식 아키텍처의 애플리케이션을 소형의 마이크로서비스 구성요소로 나누게 되면 각 구성요소가 다른 구성요소와 완전히 분리되는 이점을 얻게 됩니다. 이는 마이크로서비스 아키텍처가 제공하는 민첩성, 확장성, 복원성의 이점을 실현할 수 있습니다.

마이크로서비스는 독립적으로 구축되어 서로 커뮤니케이션 하게 되고, 장애가 개별적으로 발생하기 때문에 전체의 운영 중단으로 확대 되지 않습니다. 서비스간의 커뮤니케이션이 바로 마이크로서비스를 가능하도록 하는 핵심입니다. 


커뮤니케이션을 통제하는 로직은 Service Mesh 없이 각 서비스에 코딩 될 수 있습니다. 많은 라이브러리와 프레임워크를 이용하여 Circit Breaker 패턴을 구현할 수 있으며, 로드밸런싱 및 버전 기반 라우팅 기능을 구현할 수있습니다. 하지만 이러한 기능 구현은 마이크로서비스 구성요소에 내장되어 코드의 복잡성을 증가시킨다.

마이크로서비스 아키텍처에서는 kubernetes와 같은 컨테이너 오케스트레이션 도구를 통해 마이크로서비스 구성요소들을 대규모로 관리합니다. 

Kubernetes 자체는 런타임 환경에서 다른 마이크로서비스에 대한 Service Discovery 기능을 기본으로 제공하고, 컨테이너에 대한 동적 로드 밸런싱 기능을 제공합니다.

Service Mesh는 애플리케이션 런타임 환경에서 새로운 기능을 추가로 요구하지 않습니다.
 
 아키텍처 내의 애플리케이션에는 요청이 A 지점에서 B지점으로 전달되는 방식을 지정하는 룰이 필요합니다. Service Mesh는 개별 서비스로부터 서비스 간 커뮤니케이션을 통제하는 로직을 통해 인프라 계층에 이를 추상화하는 역할을 담당합니다. 

Service
Mesh는 어플리케이션 내부 경계에서 마이크로서비스 간의 모든 직접적인 상호통신을 차단하고, 라우팅, 복원력 및 보안 패턴과 같은 요소를 마이크로서비스 자체와 완전히 독립적으로 도입하여 관리합니다.

<br/>

### **API Management, Service Mesh 비교**

<div style="text-align: center;">

![](/img/03_Bizdevops/07/03/image101.png)

</div>

API Management와 Service Mesh는 서로 다른 범위에서 적용됩니다. API Management는 마이크로서비스 그룹의 API가 다른 그룹에 노출되는 방식에 중점을 두며, Service Mesh는 그룹 안에서 라우팅을 제공합니다.

<span class="underline">API Management 는 일반적으로 Gateway 프록시 패턴을 사용해서 수행</span>됩니다.
 
 API 호출자는 API 구현내용을 알 필요 없습니다. Gateway를 호출하는 방법만 알면 Gateway가 API 구현내용에 대한 리디렉션을 대신 수행합니다. 트래픽 관리 또는 경로 기반 라우팅 같은 상호 연결 패턴은 API Gateway에 의해 수행됩니다. (API gateway 구성은 API Management의 구성요소)

이에 반해 <span class="underline">Service Mesh는 일반적으로 Side Car Proxy 패턴을 사용</span>합니다. Gateway가 없으며, 호출자는 Mesh내에서 존재합니다.
 
 따라서 Mesh의 양쪽에는 호출자와 공급자가 있습니다. 호출자의 코드에는 공급자의 주소를 찾는 방법과 공급자의 호출에 대한 밸런싱을 유지하는 로직, 또한 재시도를 수행할지 또는 Circit Braker 와 같은 패턴을 구현할지 에 대한 내용이 들어가게됩니다. 

Service Mesh를 이용하면 이런 Sevice Mesh기능을 제공하는 호출자의 코드는 어플리케이션 코드내 내장되는 것이 아니라 Sidecar와 같이 별개로 관리 됩니다. Sidecar의 작업의 대부분은 다운 스트림 호출을 관리하는 것이며, 이는 대부분의 상호 통신 패턴이 API Management에서와 같이 서버에서 관리되는 것이 아니라, 클라이언트에서 수행되고 있음을 의미합니다.

<br/>

다음은 API Management와 Service Mesh의 차이점에 대한 표입니다.

<h5>

|                   | API Management                                                     | Service Mesh                                                                |
| ----------------- | ------------------------------------------------------------------ | --------------------------------------------------------------------------- |
| Service Discovery | 사용자가 서비스를 사용할 수 있는 API를 자체적으로 제공함                                  | 필요한 서비스를 찾기 위해서는 클라이언트 Sidecar 에서 사용하는 서비스 레지스트리를 유지관리 해야 함                 |
| 라우팅 주체            | 서버 측                                                               | 요청하는 서비스                                                                    |
| 라우팅 구성요소          | 별도의 네트워크(hop)을 도입하는 독립적인 API gateway 구성요소                          | Local Network 스택의 일부가 되는 클라이언트의 sidecar                                     |
| 로드밸런싱             | API Gateway는 단일 엔드포인트를 제공하고, 로드밸런싱 구성요소에 요청을 리디렉션하여 로드밸런싱 구성요소가 처리 | 서비스 레지스트리에서 서비스 목록을 수신하고, 이를 기반으로 클라이언트 sidecar에서 로드밸런싱 알고리즘을 통해 수행         |
| 범위                | 하나의 API gateway가 많은 응용프로그램의 API를 노출                                | Kubernetes 네임스페이스 내의 컨테이너와 같이 응용프로그램이 밀접하게 관련된 마이크로서비스 구성요소 세트로 제한          |
| 네트워크              | 외부 네트워크와 내부 애플리케이션 네트워크 사이에 위치함                                    | 응용 프로그램의 네트워크 경계 내에서만 통신을 가능하게 함(예를 들어 Kubernetes 의 Namespace 네트워크 범위)      |
| 로그 및 매트릭          | API Gateway를 통한 전체 호출에 대한 집계                                       | Mesh 범위 내에서 교차 컴포넌트 추적                                                      |
| Analytics         | API 사용자, 공급자에 대한 모든 호출에 대해서 수집되고 분석 되어짐                            | Mesh 내 모든 마이크로서비스 구성요소에 대해 다른 별도 구성요소를 통해 분석할 수 있음 (데이터 정렬/분석은 mesh 역할이 아님) |

</h5>

사용되는 보안 모델에도 차이가 있습니다. 예를 들어 API Management는 노출된 API를 보호하기 위해 HTTP인증, OAuth 및 애플리케이션 카/패스워드 쌍과 같은 기술을 상용하는 반면에, Service Mesh는 상호 서비스간에 TLS를 시행하는데 사용되며 Mesh내 구성요소간 세부적인 역할 기반 엑세스 제어를 지원합니다.

API Management (API Gateway)와 Service mesh는 서로 독립적인 역할을 가지고 있으며, 이들간의 경계를 파악하는 것이 매우 중요합니다. API Gateway의 주된 목적은 네트워크 외부의 트래픽을 받아서 내부에 배포하는 것이고, Service Mesh는 네트워크 내의 트래픽을 라우팅하고 관리하는 데 있습니다. 

Service Mesh는 API Gateway와 함께 작동하여, 외부 트래픽을 효율적으로 수신한 다음, 네트워크에서 트래픽을 효과적으로 라우팅 하도록 설계해야 합니다. API Gateway와 Service Mesh가 있는 배포에서 클러스터 외부에서 들어오는 트래픽이 먼저 API Gateway를 통해 라우팅 된 다음, Service Mesh로 라우팅 됩니다. 

API Gateway는 인증, 라우팅 등의 오프로드 기능을 처리할 수 있는 반면에 Service Mesh는 마이크로서비스 아키텍처에 대한 세밀한 관찰과 제어 기능을 제공합니다.

최근 추세를 보면 Service Mesh 기술이 매우 빠르게 발전하고 있어서 API Gateway의 일부 기능을 지원하고 있습니다.

Docker 컨테이너와 Kubernetes와 같은 컨테이너 오케스트레이션 툴을 사용하는 조직이 늘어남에 따라 Service Mesh와 API Gateway 기능이 병합될 가능성이 높습니다.

<br/>

### Service Mesh 패턴

**1. Library**

<div style="text-align: center;">

![](/img/03_Bizdevops/07/03/image102.png)

</div>

라이브러리 방식은 간단합니다. 각 마이크로 서비스 응용프로그램에는 Service Mesh 기능을 구현하는 라이브러리 코드가 포함됩니다.(Hystrix, Ribbon과 같은 라이브러리) 이는 하나의 개발 언어와 프레임워크 등의 환경에서 구현된 어플리케이션에 적합합니다. 

라이브러리 방식은 인프라 환경과의 많은 호환성을 필요로 하지 않습니다. 컨테이너 오케스트레이션(eg. Kubernetes)은 Hystrix 라이브러리가 적용되더라도 따로 설정하지 않아도 됩니다. 그러나 언어 사용에 있어서 라이브러리 방식은 제한이 있습니다. 

이러한 라이브러리를 이용해 어플리케이션은 Service Mesh의 기능을 사용하게 되며, 이 작업은 마이크로서비스의 컨텍스트에서 수행되기 때문에 CPU, 메모리와 같은 리소스를 공정하게 할당하기가 쉽습니다.

<br/>

**2. Node Agent (Shared host Proxy)**

<div style="text-align: center;">

![](/img/03_Bizdevops/07/03/image103.png)

</div>

노드 에이전트 방식에서 모든 노드(Container Instance, GCE)에서 실행되는 agent를 두고, 작업 부하를 처리합니다. 이 방식에서 어플리케이션 구현 언어는 중요하지 않습니다. 노드 에이전트 방식의 대표 적인 예로 Linkerd 가 있습니다. 모든 노드에는 하나의 노드 Agent가 필요하기 떄문에 이 방식에서는 인프라와의 호환성이 필요합니다. 

수 백에서 수천 대의 인스턴스와 순간적으로 인스턴스를 다시 스케줄링 하는 오케스트레이션 도구에서 단일 요청이 서비스의 토폴로지를 따라가는 경로는 매우 복잡하며, 컨테이너를 사용하면 각 서비스를 쉽게 구성할 수 있기 때문에 라이브러리 방식은 마이크로서비스 환경에서 비효율적입니다.

노드 에이전트 방식에서 Service Mesh는 TCP/IP와 유사합니다. TCP 스택이 네트워크 종단점간에 바이트를 안정적으로 전달하는 메커니즘을 추상화하는 것처럼 Service Mesh는 서비스간에 안정적으로 요청을 전달하는 메커니즘을 추상화합니다. TCP와 마찬가지로 Service Mesh도 실제 페이로드나 인코딩 방법에 신경 쓰지 않습니다. 

응용 프로그램의 목표(A에서 B로 보내기와 같은)를 가지고 있으면 TCP와 마찬가지로 Service Mesh는 목표를 달성하는 동시에 오류도 처리합니다. TCP 와 달리 Service Mesh는 그 외 응용 프로그램 런타임에 대한 가시성과 제어기능 등을 제공합니다. 

Service mesh의 목표는 서비스 커뮤니케이션을 보이지 않는 인프라 영역에서 모니터링, 관리 및 제어할 수 있는 일종의 레이어로 추상화는 데 있습니다.

노드 에이전트 방식의 작동 과정에 대한 이해를 돕기 위하여 Linkerd를 예로 들어 설명합니다.

Linkerd를 통해 서비스에 대한 요청이 있을 때 다음과 같이 처리 됩니다.

- Linkerd는 동적 라우팅 규칙을 적용하여, 요청자가 의도한 서비스를 찾습니다.

- 올바른 대상 서비스를 찾으면 Linkerd는 해당 서비스 엔드포인트에서 노드(GCE)의 해당 풀을 검색합니다.

- Linkerd는 최근 요청에 대한 관찰된 대기시간을 포함하여 다양한 요인을 기반으로 빠른 응답을 반환할 가능성이 가장 높은 노드를 선택합니다.

- Linkerd는 노드에 요청을 보내고 결과의 대기 시간과 응답 유형을 기록합니다.

- 노드가 다운되거나 응답이 없거나 요청을 처리하지 못한 경우 Linkerd는 다른 노드에서 요청을 다시 시도합니다.(단, 요청이 먹통인 경우 에만)

- 노드가 오류를 지속적으로 반환하는 경우 Linkerd는 이를 로드밸런싱 풀에서 제거하여 나중에 주기적으로 다시 시도합니다.(예, 노드에서 일시적인 오류가 발생할 수 있음)

- 요청 마감시간이 경과하면 Linkerd는 추가 재시도를 하는 대신 사전에 요청을 실패 처리합니다.

- Linkerd는 위의 모든 동작을 매트릭화하여, 중앙 집중식 매트릭 시스템에 전송합니다.

노드 에이전트 방식의 경우 동일한 호스트에 많은 컨테이너가 존재하는 경우, Sidecar 방식에 비해 처리량이 높고, 리소스를 적게 사용합니다. 

그러나 노드에이전트(linkerd proxy)가 장애가 나는 경우 해당 호스트에 있는 모든 컨테이너에 요청을 전달 할 수 없게 되며, 다른 Service Mesh와 같이 사용할 수 없습니다.

<br/>

**3. Sidecar (Recommended)**

<div style="text-align: center;">

![](/img/03_Bizdevops/07/03/image104.png)

</div>

Sidecar 방식은 Envoy와 함께 Istio에서 사용하는 방식입니다. Sidecar 배포에서 모든 응용 프로그램 컨테이너에 추가로 Sidecar 컨테이너가 배포됩니다. Sidecar는 응용 프로그램 컨테이너로 들어오거나 나가는 모든 네트워크 트래픽을 처리합니다. 이 방식은 라이브러리와 노드에이전트 방식과 큰 차이점을 가집니다. 

예를 들어 모든 노드에서 새 에이전트를 실행할 필요 없이 Sidecar를 배포할 수 있으므로(노드 에이전트를 배포하기 위해 인프라 전반에 협업이 필요하지 않음) 동일한 Sidecar의 복사 본을 여러 개 실행합니다. 또한 Linkerd에서 마이크로서비스 그룹에 하나의 Service Mesh만을 사용하던 것과 달리 다른 Service Mesh와 같이 사용할 수 있습니다. 

Sidecar 방식에서 GKE의 경우, POD 정의에 프록시가 정의됩니다. 일반적으로 1Container 당 1 Sidecar 방식으로 사용되며, 단일 호스트로의 proxy오류 가능성을 제한하며, 동일한 호스트의 단일 호스트에는 영향을 미치지 않습니다.

<br/>

#### Service Mesh 주요 기능

Service Mesh의 주요한 목표는 서비스 통신 계층에 대한 가시성을 확보하고 동적으로 서비스를 디스커버리, 로드 밸런싱, 타임아웃처리, 폴백, 재시도, Circuit Breaker, 분산형 추적 과 같은 모든 마이크로서비스 통신 논리를 완벽하게 제어하는 데 있습니다. 서비스 간의 보안 정책 적용 및 가시성 확보 등은 트래픽 제어 및 trace 기능에 의해 제공됩니다.

GCP의 GKE는 이미 기본적인 Service Mesh를 가지고 있습니다. 그것은 ‘서비스(Service)’ 리소스 입니다. 필요한 Pod/Task를 대상으로 서비스 검색을 제공하고, 요청에 대한 라운드로빈 방식으로 밸런싱을 처리합니다. 

서비스는 클러스터의 각 호스트에서 iptable을 관리하여 재시도 및 논리 연결 해제 없이 라운드 로빈 로드밸런싱 방식과 같은 기초적인 기능만을 지원하고, 앞에 나열한 Service Mesh풍부한 기능은 기대할 수 없습니다. 

그러나 컨테이너 클러스터 환경에서 Service Mesh(Linkerd, istio, consul)을 구현하면 다음과 같은 기능을 사용할 수 있습니다.

1. HTTP/HTTPS

> Service Mesh 프록시는 발신 측에서 HTTPS 캡슐화를 관리하고 수신 측에서 TLS 종단을 관리하여 응용 프로그램의
> 구성요소가 일반 HTTP 또는 gRPC 및 기타 프로토콜을 사용할 수 있게 합니다. 또한 전송 중 암호화에 신경 쓰지 않아도
> 됩니다. 암호화는 프록시에 의해 처리됩니다.

2. 보안 정책

> 프록시는 어떤 서비스가 다른 서비스 및 엔드포인트에 액세스하도록 허용되는지를 알고 허락되지 않은 트래픽을 거부합니다.

3. Circuit Breaking

> 오버로드된 서비스 또는 엔드포인트에 엑세스 할 때, 자동으로 백오프 (대기시간이 너무 길어서 과도한 로드로 인해 엔드포인트가 완전히 실패할 수 있는 요청이 증가하는 것을 피하기 위해서)

4. 지연시간 기반 로드밸런싱

> 각 대상의 대기시간을 무시하는 라운드 로빈 스타일의 로드밸런싱 대신 각 백엔드 대상의 응답시간에 따라 스마트한 로드밸런싱을 사용합니다.

5.  대기열 기반의 로드밸런싱

> Service Mesh는 이전의 모든 요청을 보낸 곳과 처리 중이거나 완료 한 곳을 정확히 알고 있으므로 처리를 위해 가장 낮은 대기열을 가진 대상에 해당 로직을 기반으로 새로운 수신 요청을 보냅니다.

6.  요청 라우팅

> HTTP 헤더를 읽어서 요청을 로드밸런서 뒤에 있는 특정 대상으로 라우팅합니다. 이 기능을 이용해 카나리아 배포 테스트 등을 할 수 있습니다. Service Mesh에서 제공하는 가장 강력한 기능 중 하나입니다.

7. Health Check, 재시도

8.  매트릭 및 Trace

> 대기시간 매트릭, 요청 성공/오류율

<br/>

### **Service Mesh 종류**

서비스 매시는 크게 MS Azure Service Fabric과 같이 PaaS의 일부로서 서비스 코드에 포함되는 유형과 Netflix OSS와 같이 라이브러리로 구현되어 API호출을 통해 매시에 결합되는 유형 및 Istio, Linkerd와 같이 Side Code 프락시를 사용하여 메시 기능을 마이크로서비스에 주입하는 유형으로 분류됩니다.

<div style="text-align: center;">

![](/img/03_Bizdevops/07/03/image105.png)

</div>

<br/>

**1. AWS App Mesh**
([<span class="underline">https://aws.amazon.com/ko/app-mesh/features/</span>](https://aws.amazon.com/ko/app-mesh/features/))\]

AWS App Mesh를 사용하면 다양한 유형의 컴퓨팅 인프라 전반에 구축된 서비스에 대한 일관된 가시성 및 네트워크 트래픽 제어 기능을 제공하여 손쉽게 서비스를 실행할 수 있으며, 모니터링 데이터 수집 방식이나 서비스 간에 트래픽이 라우팅 되는 방식을 변경하기 위해 애플리케이션 코드를 업데이트할 필요가 없습니다. 

App Mesh는 모니터링 데이터를 내보내도록 각 서비스를 구성하고, 애플리케이션 전반에 일관된 통신 제어 로직을 구현합니다. 

이를 통해 오류의 정확한 위치를 신속하게 찾아내고 오류가 있거나 코드 변경 사항을 배포해야 하는 경우 네트워크 트래픽을 자동으로 다시 라우팅 할 수 있습니다.

AWS Fargate, Amazon ECS, Amazon EKS, Kubernetes on EC2와 함께 App Mesh를 사용하면 규모에 맞춰 컨테이너화된 마이크로서비스를 효과적으로 사용할 수 있습니다.

AWS APP Mesh의 주요 기능은 다음과 같습니다.

- 일관된 마이크로서비스 통신 : App Mesh는 통신 모니터링과 제어에 필요한 논리를 각각의 마이크로서비스 대한 모든 네트워크 트래픽을 관리하는 프록시로 나눕니다.

- 오픈소스 프록시 : App Mesh는 마이크로서비스 컨테이너로 오가는 모든 트래픽을 관리하기 위해 오픈소스인 Envoy 프록시를 설정합니다.

- 가시성 : App Mesh는 마이크로서비스 간 모든 통신에 대한 수치, 로그, 트레이스를 모으기 때문에 에러 발생 부분을 빠르게 처리할 수 있습니다. 이 기능은 AWS 서비스와 오픈 소스를 이용하여 실행 가능합니다.

- 트래픽 제어 : App Mesh는 어플리케이션 내부 코드 수정이나 로드밸런서를 사용하는 일 없이 마이크로서비스들을 바로 연결할 수 있도록 하며, 각 마이크로서비스가 시작할 때, 마이크로서비스의 프록시가 App Mesh에 연결하고
    어플리케이션 내 다른 마이크로서비스들의 위치를 담고 있는 데이터를 받습니다.

<br/>

**2. Istio **
([<span class="underline">https://istio.io/docs/concepts/what-is-istio/</span>](https://istio.io/docs/concepts/what-is-istio/))**

Istio는 Google, IBM, Redhat, Lyft, VMware와 같이 다수의 대형업체들이 참여하여 Service Mesh의 개념을 쉽게 구현할 수 있는 일종의 프레임워크(?)의 형태로 제공하는 오픈소스입니다. 

그리고 이를 통해 대규모의 마이크로서비스 환경이라고 하여도 서비스를 연결, 보안, 제어 및 관찰할 수 있는 방안을 쉽게 하도록 지원하고 있습니다.

Istio의 주요 기능은 다음과 같습니다.

- 트래픽 관리 : Istio의 간단한 룰 설정과 트래픽 라우팅은 사용자로 하여금 서비스 간 트래픽과 API 요청의 흐름을 조절할 수 있게 합니다. Istio는 circuit breakers, timeouts, retries 같은 서비스 레벨의 속성들의 설정을 단순화 하고, A/B Testing, Canary Rollouts, 백분위 단위의 traffic 분산으로 단계적 rollouts 같은 중요한 일들을 설정하기 쉽도록 합니다.

- 보안 : Istio는 마이크로 서비스 간 통신의 인증, 승인, 암호화를 확장 가능한 방식으로 제공 및 관리할 수 있습니다.
    특히, Istio 가 기본적으로 기반 보안 통신 채널을 제공하므로 이를 통해 개발자는 애플리케이션 수준 보안에 집중할 수 있으며, 별도의 보안에 대한 고민 없이도 Istio 가 안전한 보안 커뮤니케이션을 지원할 수 있습니다.

- 관측 : Istio는 기본적으로 추적, 모니터링, 로깅을 제공 가능하며 이를 통해 Service Mesh 배포에 대한 심층적인 정보를 제공하여 서비스의 성능과 다른 프로세스에 미치는 성능의 영향을 확인하고 문제를 빠르고 효과적으로 감지 및 분류할 수 있도록 지원할 수 있습니다..

- 플랫폼 지원 : Istio는 플랫폼에 독립적이고, 다양한 클라우드, On-premise, Kubernetes, Mesos 같은 다양한 환경에서 돌아가도록 설계 되었습니다.

- 통합 및 사용자 정의 : Istio의 정책 실행 구성요소는 ACLs, Logging, Monitoring, Quotas, Auditing 등 기존의 솔루션들과 통합되도록 확장 및 사용자 정의가 가능합니다.

<br/>

### **Service Mesh 고려사항**

Service Mash Pattern에서 설명한 것처럼 Service Mesh 패턴은 다양합니다. 패턴들을 크게 두 가지로 크게 분류하면 호스트 공유 프록시 패턴과 Side car 컨테이너 방식이라 할 수 있습니다.

<div style="text-align: center;">

![](/img/03_Bizdevops/07/03/image106.png)

</div>

**Host Shared Proxy 패턴**

Kubernetes 용어로는 Daemonset이라 부른다. 동일한 호스트에 많은 컨테이너가 존재하고 연결 풀링을 활용하여 처리량을 향상시키는 경우에는 더 적게 리소스를 사용합니다. 

그러나 하나의 프록시가 실패하면 해당 호스트에 있는 모든 컨테이너들이 종료됩니다. 대표적인 service mesh 제품은 linkerd 입니다.

<br/>

**Sidecar 컨테이너 패턴**

메인 응용 어플리케이선 컨테이너 서비스와 함께 실행되도록 각 pod 또는 task 정의에 프록시가 주입됩니다. 단일 호스트로의 프록시 오류 가능성을 제한하며 동일한 호스트의 다른 호스트에는 영향을 미치지 않습니다. 

Linkerd 역시 sidecar 컨테이너에 주입하여 사용할 수 있습니다. 이 방식의 대표적인 service mesh 제품은 istio 입니다.

<br/>

**Service Mesh 미 구성 아키텍처**

<div style="text-align: center;">

![](/img/03_Bizdevops/07/03/image107.png)

</div>

위 그림은 Service mesh가 고려되지 않은 마이크로서비스 아키텍처를 나타냅니다. 방문자 패턴과 환경 설정을 학습하여 웹사이트에서 자신의 경험을 개인화하고, 사용자에게 좋아하는 주제 업데이트를 알리는 등의 일을 하는 응용 프로그램을 제공합니다. 

<br/>

**Service Mesh 적용 아키텍처**

<div style="text-align: center;">

![](/img/03_Bizdevops/07/03/image108.png)

</div>


이 아키텍처의 주요한 특징은 Service Mesh컨트롤 플레인(또는 일부 저장소의 구성 파일을 통해 선택한 도구 및 배포 방법에 따라 다름)을 통해 동일한 위치에서 프록시를 구성하고 업데이트 할 수 있다는 점입니다. 

모든 수천 개의 프록시에 대한 규칙을 지정하여 라우팅, 밸런싱, 매트릭 수집, 보안 정책, Circuit Breaker, 암호화 전송 등의 모든 작업은 클러스터 관리자가 적용한 규칙 집합을 따르게 됩니다.

마이크로서비스 통신 메커니즘을 별도의 아키텍처 계층으로 분리하는 Service Mesh의 개념은 수 천개의 프록시를 구성하고 유지 관리하는 복잡성을 감당할 만큼 유익한 지에 대한 의문이 들 수 있습니다.

Istio는 완벽한 기능을 가진 Service Mesh의 예이며, 모든 데이터 플레인 프록시를 관리하는 여러 마스터 구성요소를 가지고 있습니다. (프록시는 Envoy 또는 Linkerd가 될 수 있지만 기본적으로 Envoy를 사용)

<br/><br/>